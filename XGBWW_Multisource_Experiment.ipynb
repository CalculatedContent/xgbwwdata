{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost2ww Experiment (100\u20131000 random models, multi-source datasets)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/CalculatedContent/xgbwwdata/blob/main/XGBWW_Multisource_Experiment.ipynb)\n",
    "\n",
    "This notebook keeps the original workflow and cell structure, but **replaces direct OpenML dataset calls** with the\n",
    "`xgbwwdata` package so datasets can come from multiple sources (`openml`, `pmlb`, `keel`, `libsvm`, `amlb`).\n",
    "\n",
    "It shows how to:\n",
    "- Pick a \u201cgood\u201d XGBoost model with train-only CV\n",
    "- Evaluate once on a true holdout test split\n",
    "- Build W-matrices via `xgboost2ww.convert()`\n",
    "- Run WeightWatcher diagnostics (`alpha`, `traps`, `ERG_gap`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick Matrix W1 | W2 | W7 | W8\n",
    "MATRIX = \"W7\"\n",
    "\n",
    "# Starter: 100, scale up to 1000\n",
    "TARGET_DATASETS = 100\n",
    "\n",
    "# Multi-source scan (NOT OpenML-only)\n",
    "DATA_SOURCES = [\"openml\", \"pmlb\", \"keel\", \"libsvm\", \"amlb\"]\n",
    "\n",
    "# Optional cap per source pass via scan limit\n",
    "SCAN_LIMIT = max(TARGET_DATASETS * 3, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up folder on Google Drive to save final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "drive.mount(\"/content/drive\", force_remount=False)\n",
    "GDRIVE_DIR = \"/content/drive/MyDrive/xgboost2ww_runs\"\n",
    "os.makedirs(GDRIVE_DIR, exist_ok=True)\n",
    "print(\"Saving results under:\", GDRIVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System deps\n",
    "!apt-get -qq update && apt-get -qq install -y git\n",
    "\n",
    "# Python deps for this notebook\n",
    "%pip install -q -U pip setuptools wheel\n",
    "%pip install -q \"pandas==2.2.2\" xgboost weightwatcher scikit-learn scipy pyarrow xgboost2ww\n",
    "\n",
    "# Install xgbwwdata from fresh clone (same flow as README / XGBDataTest)\n",
    "!rm -rf /content/repo_xgbwwdata\n",
    "!git clone https://github.com/CalculatedContent/xgbwwdata.git /content/repo_xgbwwdata\n",
    "%run /content/repo_xgbwwdata/scripts/colab_install.py --repo /content/repo_xgbwwdata\n",
    "\n",
    "import xgboost2ww\n",
    "import xgbwwdata\n",
    "print(\"xgboost2ww:\", getattr(xgboost2ww, \"__file__\", None))\n",
    "print(\"xgbwwdata:\", getattr(xgbwwdata, \"__file__\", None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, time, gc\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "import torch\n",
    "import weightwatcher as ww\n",
    "\n",
    "from xgbwwdata import Filters, scan_datasets, load_dataset, enable_logging\n",
    "from xgboost2ww import convert\n",
    "\n",
    "RNG = 0\n",
    "rng = np.random.default_rng(RNG)\n",
    "\n",
    "TEST_SIZE = 0.20\n",
    "NFOLDS = 5\n",
    "T_TRAJ = 160\n",
    "\n",
    "MAX_ROWS = 60000\n",
    "MAX_FEATURES_GUARD = 50_000\n",
    "MAX_DENSE_ELEMENTS = int(2e8)\n",
    "\n",
    "GOOD_TRIALS = 5\n",
    "CV_MAX_ROUNDS = 3000\n",
    "CV_EARLY_STOP = 150\n",
    "MIN_GOOD_TEST_ACC = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: GPU detection for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_gpu_available() -> bool:\n",
    "    try:\n",
    "        Xtmp = np.random.randn(256, 8).astype(np.float32)\n",
    "        ytmp = (Xtmp[:, 0] > 0).astype(np.int32)\n",
    "        dtmp = xgb.DMatrix(Xtmp, label=ytmp)\n",
    "        params = dict(\n",
    "            objective=\"binary:logistic\",\n",
    "            eval_metric=\"logloss\",\n",
    "            tree_method=\"gpu_hist\",\n",
    "            predictor=\"gpu_predictor\",\n",
    "            max_depth=2,\n",
    "            learning_rate=0.2,\n",
    "            seed=RNG,\n",
    "        )\n",
    "        _ = xgb.train(params=params, dtrain=dtmp, num_boost_round=5, verbose_eval=False)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "USE_GPU = xgb_gpu_available()\n",
    "print(\"XGBoost GPU available:\", USE_GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover datasets with xgbwwdata (multi-source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_logging()\n",
    "\n",
    "filters = Filters(\n",
    "    min_rows=200,\n",
    "    max_rows=MAX_ROWS,\n",
    "    max_features=MAX_FEATURES_GUARD,\n",
    "    max_dense_elements=MAX_DENSE_ELEMENTS,\n",
    "    preprocess=True,\n",
    ")\n",
    "\n",
    "df_registry = scan_datasets(\n",
    "    sources=DATA_SOURCES,\n",
    "    limit=SCAN_LIMIT,\n",
    "    filters=filters,\n",
    "    smoke_train=True,\n",
    "    random_state=RNG,\n",
    "    log_every=25,\n",
    ")\n",
    "\n",
    "print(\"Candidates found:\", len(df_registry))\n",
    "display(df_registry.head(10))\n",
    "print(df_registry[\"source\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a \u201cgood\u201d XGBoost model using training-only CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_good_params_via_cv(Xtr, ytr, nfold=5, *, dataset_seed: int):\n",
    "    dtrain = xgb.DMatrix(Xtr, label=ytr)\n",
    "    local_rng = np.random.default_rng(RNG + int(dataset_seed))\n",
    "\n",
    "    best = None\n",
    "    best_score = np.inf\n",
    "\n",
    "    for _ in range(GOOD_TRIALS):\n",
    "        params = dict(\n",
    "            objective=\"binary:logistic\",\n",
    "            eval_metric=\"logloss\",\n",
    "            tree_method=\"hist\",\n",
    "            seed=RNG,\n",
    "            learning_rate=float(10 ** local_rng.uniform(-2.0, -0.6)),\n",
    "            max_depth=int(local_rng.integers(2, 7)),\n",
    "            min_child_weight=float(10 ** local_rng.uniform(0.0, 2.0)),\n",
    "            subsample=float(local_rng.uniform(0.6, 0.9)),\n",
    "            colsample_bytree=float(local_rng.uniform(0.6, 0.9)),\n",
    "            reg_lambda=float(10 ** local_rng.uniform(0.0, 2.0)),\n",
    "            gamma=float(local_rng.uniform(0.0, 0.5)),\n",
    "        )\n",
    "        if USE_GPU:\n",
    "            params[\"tree_method\"] = \"gpu_hist\"\n",
    "            params[\"predictor\"] = \"gpu_predictor\"\n",
    "\n",
    "        cv = xgb.cv(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=CV_MAX_ROUNDS,\n",
    "            nfold=nfold,\n",
    "            stratified=True,\n",
    "            early_stopping_rounds=CV_EARLY_STOP,\n",
    "            seed=RNG,\n",
    "            verbose_eval=False,\n",
    "        )\n",
    "\n",
    "        score = float(cv[\"test-logloss-mean\"].iloc[-1])\n",
    "        rounds = int(len(cv))\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best = (params, rounds, score)\n",
    "\n",
    "    return best\n",
    "\n",
    "\n",
    "def train_eval_fulltrain(Xtr, ytr, Xte, yte, params, rounds):\n",
    "    dtr = xgb.DMatrix(Xtr, label=ytr)\n",
    "    dte = xgb.DMatrix(Xte, label=yte)\n",
    "\n",
    "    bst = xgb.train(params=params, dtrain=dtr, num_boost_round=rounds, verbose_eval=False)\n",
    "\n",
    "    m_tr = bst.predict(dtr, output_margin=True).astype(np.float32)\n",
    "    p_tr = 1.0 / (1.0 + np.exp(-m_tr))\n",
    "    train_acc = float(accuracy_score(ytr, (p_tr >= 0.5).astype(int)))\n",
    "\n",
    "    m_te = bst.predict(dte, output_margin=True).astype(np.float32)\n",
    "    p_te = 1.0 / (1.0 + np.exp(-m_te))\n",
    "    test_acc = float(accuracy_score(yte, (p_te >= 0.5).astype(int)))\n",
    "    test_loss = float(log_loss(yte, np.vstack([1 - p_te, p_te]).T, labels=[0, 1]))\n",
    "\n",
    "    return train_acc, test_acc, test_loss, bst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WeightWatcher helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ww_metrics_from_layer(layer):\n",
    "    watcher = ww.WeightWatcher(model=layer)\n",
    "    details_df = watcher.analyze(randomize=True, ERG=True, plot=False)\n",
    "    alpha = float(details_df[\"alpha\"].iloc[0]) if \"alpha\" in details_df.columns else np.nan\n",
    "    traps = float(details_df[\"num_traps\"].iloc[0]) if \"num_traps\" in details_df.columns else np.nan\n",
    "    ERG_gap = float(details_df[\"ERG_gap\"].iloc[0]) if \"ERG_gap\" in details_df.columns else np.nan\n",
    "    return alpha, traps, ERG_gap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment (xgbwwdata registry + load_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "kept = 0\n",
    "t0 = time.time()\n",
    "\n",
    "# Keep binary classification only and prefer diverse sources\n",
    "for _, rec in df_registry.sample(frac=1.0, random_state=RNG).iterrows():\n",
    "    if kept >= TARGET_DATASETS:\n",
    "        break\n",
    "\n",
    "    dataset_uid = rec[\"dataset_uid\"]\n",
    "    try:\n",
    "        X, y, meta = load_dataset(dataset_uid, filters=filters)\n",
    "    except Exception as e:\n",
    "        print(\"SKIP load:\", dataset_uid, type(e).__name__, e)\n",
    "        continue\n",
    "\n",
    "    y = np.asarray(y)\n",
    "    if len(np.unique(y)) != 2:\n",
    "        continue\n",
    "\n",
    "    if int(X.shape[1]) > MAX_FEATURES_GUARD:\n",
    "        continue\n",
    "\n",
    "    tr_idx, te_idx = train_test_split(\n",
    "        np.arange(len(y)),\n",
    "        test_size=TEST_SIZE,\n",
    "        random_state=RNG,\n",
    "        stratify=y,\n",
    "    )\n",
    "\n",
    "    Xtr, Xte = X[tr_idx], X[te_idx]\n",
    "    ytr, yte = y[tr_idx], y[te_idx]\n",
    "\n",
    "    is_sparse = hasattr(Xtr, \"tocsr\")\n",
    "    if is_sparse:\n",
    "        Xtr = Xtr.tocsr().astype(np.float32)\n",
    "        Xte = Xte.tocsr().astype(np.float32)\n",
    "        if int(Xtr.shape[0]) * int(Xtr.shape[1]) > MAX_DENSE_ELEMENTS:\n",
    "            # conservative guard for convert() if densification happens internally\n",
    "            continue\n",
    "    else:\n",
    "        Xtr = np.asarray(Xtr, dtype=np.float32)\n",
    "        Xte = np.asarray(Xte, dtype=np.float32)\n",
    "\n",
    "    seed_from_uid = abs(hash(dataset_uid)) % (2**31 - 1)\n",
    "    good_params, good_rounds, good_cv_logloss = pick_good_params_via_cv(\n",
    "        Xtr, ytr, nfold=NFOLDS, dataset_seed=seed_from_uid\n",
    "    )\n",
    "\n",
    "    good_train_acc, good_test_acc, good_test_loss, bst = train_eval_fulltrain(\n",
    "        Xtr, ytr, Xte, yte, good_params, good_rounds\n",
    "    )\n",
    "\n",
    "    if good_test_acc < MIN_GOOD_TEST_ACC:\n",
    "        del bst, X, y, Xtr, Xte, ytr, yte\n",
    "        gc.collect()\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        layer_W = convert(\n",
    "            model=bst,\n",
    "            data=Xtr,\n",
    "            labels=ytr,\n",
    "            W=MATRIX,\n",
    "            nfolds=NFOLDS,\n",
    "            t_points=T_TRAJ,\n",
    "            random_state=RNG,\n",
    "            train_params=good_params,\n",
    "            num_boost_round=good_rounds,\n",
    "            multiclass=\"error\",\n",
    "            return_type=\"torch\",\n",
    "            verbose=False,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"SKIP convert:\", dataset_uid, type(e).__name__, e)\n",
    "        del bst, X, y, Xtr, Xte, ytr, yte\n",
    "        gc.collect()\n",
    "        continue\n",
    "\n",
    "    alpha_W, traps_W, ERG_gap_W = ww_metrics_from_layer(layer_W)\n",
    "\n",
    "    rows.append(dict(\n",
    "        dataset_uid=dataset_uid,\n",
    "        source=rec.get(\"source\", \"unknown\"),\n",
    "        dataset=meta.get(\"name\", rec.get(\"name\", dataset_uid)),\n",
    "        n_rows_total=int(X.shape[0]),\n",
    "        n_train=int(Xtr.shape[0]),\n",
    "        n_test=int(Xte.shape[0]),\n",
    "        n_features=int(X.shape[1]),\n",
    "        rounds=int(good_rounds),\n",
    "        cv_logloss=float(good_cv_logloss),\n",
    "        good_train_acc=float(good_train_acc),\n",
    "        good_test_acc=float(good_test_acc),\n",
    "        good_test_loss=float(good_test_loss),\n",
    "        alpha_W=float(alpha_W),\n",
    "        traps_W=float(traps_W),\n",
    "        ERG_gap_W=float(ERG_gap_W),\n",
    "    ))\n",
    "\n",
    "    kept += 1\n",
    "    elapsed = (time.time() - t0) / 60.0\n",
    "    print(\n",
    "        f\"[{kept}/{TARGET_DATASETS}] {meta.get('name', dataset_uid)} ({dataset_uid}) \"\n",
    "        f\"| src={rec.get('source')} | train/test={good_train_acc:.3f}/{good_test_acc:.3f} \"\n",
    "        f\"| \u03b1(W)={alpha_W:.2f} traps(W)={traps_W:.1f} | elapsed={elapsed:.1f} min\",\n",
    "        flush=True,\n",
    "    )\n",
    "\n",
    "    if kept % 10 == 0:\n",
    "        batch = pd.DataFrame(rows[-10:]).reset_index(drop=True)\n",
    "        x = np.arange(len(batch))\n",
    "        w = 0.4\n",
    "\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.bar(x - w / 2, batch[\"good_test_acc\"].values, width=w, color=\"blue\", label=\"test accuracy\")\n",
    "        plt.bar(x + w / 2, batch[\"good_train_acc\"].values, width=w, color=\"red\", label=\"training accuracy\")\n",
    "        plt.xticks(x, batch[\"dataset\"].values, rotation=90)\n",
    "        plt.ylim(0.0, 1.0)\n",
    "        plt.ylabel(\"accuracy\")\n",
    "        plt.title(f\"Train/Test accuracy for models {kept - 9}-{kept}\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    del bst, layer_W, X, y, Xtr, Xte, ytr, yte\n",
    "    gc.collect()\n",
    "\n",
    "df_good = pd.DataFrame(rows)\n",
    "print(f\"DONE. datasets_kept={df_good['dataset_uid'].nunique() if len(df_good) else 0} rows={len(df_good)}\")\n",
    "display(df_good.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if len(df_good) == 0:\n",
    "    print(\"No datasets kept. Try lowering MIN_GOOD_TEST_ACC.\")\n",
    "else:\n",
    "    x = np.arange(len(df_good))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x, df_good[\"alpha_W\"].values, label=MATRIX)\n",
    "    plt.xticks(x, df_good[\"dataset\"].values, rotation=90)\n",
    "    plt.ylabel(\"alpha\")\n",
    "    plt.title(\"Alpha across datasets\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x, df_good[\"traps_W\"].values, label=MATRIX)\n",
    "    plt.xticks(x, df_good[\"dataset\"].values, rotation=90)\n",
    "    plt.ylabel(\"traps\")\n",
    "    plt.title(\"Traps across datasets\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(df_good[\"good_test_acc\"].values, df_good[\"alpha_W\"].values)\n",
    "    plt.xlabel(\"Holdout test accuracy\")\n",
    "    plt.ylabel(\"alpha_W\")\n",
    "    plt.title(f\"Holdout accuracy vs alpha({MATRIX})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional structural diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_good) == 0:\n",
    "    print(\"No results to plot.\")\n",
    "else:\n",
    "    plt.figure(); plt.hist(df_good[\"alpha_W\"].dropna().values, bins=30)\n",
    "    plt.xlabel(\"alpha_W\"); plt.ylabel(\"count\"); plt.title(f\"Histogram of alpha({MATRIX})\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    plt.figure(); plt.hist(df_good[\"traps_W\"].dropna().values, bins=30)\n",
    "    plt.xlabel(\"traps_W\"); plt.ylabel(\"count\"); plt.title(f\"Histogram of traps({MATRIX})\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    plt.figure(); plt.hist(df_good[\"ERG_gap_W\"].dropna().values, bins=30)\n",
    "    plt.xlabel(\"ERG_gap_W\"); plt.ylabel(\"count\"); plt.title(f\"Histogram of ERG_gap({MATRIX})\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(df_good[\"alpha_W\"].values, df_good[\"ERG_gap_W\"].values)\n",
    "    plt.xlabel(\"alpha_W\"); plt.ylabel(\"ERG_gap_W\")\n",
    "    plt.axvline(x=2.0, color=\"red\"); plt.axhline(y=0.0, color=\"orange\")\n",
    "    plt.title(f\"alpha({MATRIX}) vs ERG_gap({MATRIX})\")\n",
    "    plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "RESULTS_FEATHER = os.path.join(GDRIVE_DIR, f\"{MATRIX}_multisource_results_{ts}.feather\")\n",
    "\n",
    "df_good.to_feather(RESULTS_FEATHER)\n",
    "print(f\"Saved {len(df_good)} rows to: {RESULTS_FEATHER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RELOAD data from Google Drive and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "files = sorted(glob.glob(os.path.join(GDRIVE_DIR, f\"{MATRIX}_multisource_results_*.feather\")))\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"No {MATRIX}_multisource_results_*.feather files found in {GDRIVE_DIR}\")\n",
    "\n",
    "RESULTS_FEATHER = files[-1]\n",
    "print(\"Loading:\", RESULTS_FEATHER)\n",
    "\n",
    "df = pd.read_feather(RESULTS_FEATHER)\n",
    "print(\"Rows:\", len(df), \"| Cols:\", len(df.columns))\n",
    "display(df.head(10))\n",
    "\n",
    "if \"good_test_acc\" in df.columns:\n",
    "    df = df.sort_values(\"good_test_acc\", ascending=False)\n",
    "\n",
    "alpha_col = \"alpha_W\"\n",
    "traps_col = \"traps_W\"\n",
    "\n",
    "plt.figure(); plt.hist(df[alpha_col].dropna().values, bins=30)\n",
    "plt.title(f\"Distribution of alpha({MATRIX})\"); plt.xlabel(alpha_col); plt.ylabel(\"count\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(); plt.hist(df[traps_col].dropna().values, bins=30)\n",
    "plt.title(f\"Distribution of traps({MATRIX})\"); plt.xlabel(traps_col); plt.ylabel(\"count\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(); plt.scatter(df[\"good_test_acc\"].values, df[alpha_col].values)\n",
    "plt.xlabel(\"good_test_acc\"); plt.ylabel(alpha_col)\n",
    "plt.title(f\"alpha({MATRIX}) vs test accuracy\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "if \"good_train_acc\" in df.columns:\n",
    "    gap = df[\"good_train_acc\"].values - df[\"good_test_acc\"].values\n",
    "    plt.figure(); plt.scatter(gap, df[alpha_col].values)\n",
    "    plt.xlabel(\"train - test accuracy gap\"); plt.ylabel(alpha_col)\n",
    "    plt.title(f\"alpha({MATRIX}) vs generalization gap\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "summary_cols = [c for c in [\"dataset\",\"dataset_uid\",\"source\",\"good_train_acc\",\"good_test_acc\",alpha_col,traps_col,\"rounds\"] if c in df.columns]\n",
    "print(\"Top 15 by test accuracy:\")\n",
    "display(df[summary_cols].head(15))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}